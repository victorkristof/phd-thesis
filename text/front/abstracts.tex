% English abstract
\cleardoublepage
\chapter*{Abstract}
\markboth{Abstract}{Abstract}
\addcontentsline{toc}{chapter}{Abstract / Résumé} % adds an entry to the table of contents

From the lack of transparency in democratic processes to the spread of conspiracy theories to the rise in greenhouse gas emissions, global problems stemming from the decisions and behaviors of people can seem intractable and unpredictable.
Fortunately, people are more predictable than we think, and with large enough datasets and machine-learning algorithms, we can design accurate models of human behavior in a variety of settings.
In this thesis, we develop probabilistic models of choice processes to discover insights into social processes.
We focus on designing models that are highly interpretable by drawing from the econometrics literature on discrete-choice models, which we combine with latent-factor models, Bayesian statistics, and generalized linear models.
These predictive models enable interpretability through their learned parameters and latent factors.

First, we study the social dynamics behind group collaborations for collective content creation, such as in Wikipedia and the Linux kernel.
By combining the Rasch model with latent factors reminiscent of collaborative filtering, we develop a model of the probability that an edit is accepted.
% In peer-production systems, users with shared but competing interests attempt to edit components of the system.
% We posit that the probability that an edit is accepted is a function of the editor’s skill, of the difficulty of editing the component, and of a user-component interaction term.
The model parameters lead to a ranking of "hard-to-edit" components and influential users.
The latent representations capture non-linear interactions between users and components and cluster well into different topics.
% Our model is general, achieves high predictive performance, and enables interpretability.
% We obtain a ranking of "hard-to-edit" components, which correlates well with ad-hoc rankings of controversial items.
% Our approach also learns latent representations of users and components, which clusters well into different topics.

Second, we study the competitive dynamics of the law-making process in the European Union through the lens of peer-production systems.
% Because of its transparency in documenting the creation of laws, we study the competitive dynamics of the legislative process in the European Union.
% We take a graph-theoretical perspective to characterize this process by analyzing the \emph{edit graph} of law proposals.
We model the adoption of law edits by combining the above model with the Bradley-Terry model and enhancing it with techniques from natural language processing.
% Our model combines (a) explicit features of the parliamentarians, the laws, and the edits, (b) latent features of the parliamentarians and laws, and (c) text features of the edits.
This enables us to discover controversial laws, words and features of the parliamentarians that correlate with high probability of edit acceptance, and representations of laws in an ideological space.

Third, we develop an algorithm for predicting the popular vote of elections by combining matrix factorization and generalized linear models.
Our algorithm learns representations of votes and regions to capture ideological and cultural voting patterns (\textit{e.g.}, liberal/conservative and rural/urban) and makes predictions for unobserved regions on new votes from partial results.
We test our model on synthetic data in Germany, Switzerland, and the United States, and we deploy it on a Web platform to predict Swiss referendum votes in real-time.
% Our predictions reach less than 1\% of error by observing less than 5\% of the regions.

Fourth, by observing that human choices are guided by our perception of our environment, we study how people perceive the carbon footprint of their day-to-day actions.
We cast this problem as a comparison problem between pairs of actions (\textit{e.g.}, the difference between intercontinental flights versus using household appliances) and develop a statistical model of relative comparisons reminiscent of the Thurstone model in psychometrics.
The model learns the users’ perception as the parameters of a Bayesian linear regression, which enables us to derive an active-learning algorithm to collect data efficiently.
% We enrich our model by incorporating perception biases (\textit{e.g.}, cultural, political, and gender) to interpret our results at a finer level of socio-demographics features.

Finally, we develop a probabilistic model of pairwise-comparison outcomes that can capture a wide range of time dynamics.
% We achieve this by replacing the static parameters of a class of popular pairwise-comparison models by continuous-time Gaussian processes.
We also develop an efficient inference algorithm that computes an approximate Bayesian posterior distribution with only a few linear-time iterations over the data.
We apply this algorithm to sports, and we deploy it on a Web platform to predict football matches in European leagues.

\paragraph{Keywords}
discrete-choice models, latent-factor models, comparisons, choices, probabilistic models, data mining, machine learning, computational social science

\cleardoublepage

% French abstract
\begin{otherlanguage}{french}
	\chapter*{Résumé}
	\markboth{Résumé}{Résumé}

	Nous, humains, sommes des machines à comparer.
	Faire une comparaison et choisir un objet ou un concept parmi un ensemble d'alternatives est sans doute l'une des façons les plus naturelles d'exprimer nos préférences et nos opinions.
	Dans le cadre de beaucoup d'applications pratiques, l'analyse de données sous forme de comparaisons permet de trouver des informations précieuses.
	Mais les jeux de données recueillis contiennent souvent des résultats de comparaisons en contradiction les uns avec les autres, parce que nos préférences changent et que les comparaisons observées sont contaminées par du bruit.
	Une approche raisonnée pour traiter de telles données intransitives consiste à postuler un modèle probabiliste de comparaisons.
	Dans cette thèse, nous revisitons le modèle de choix proposé par Luce (dont l'étude remonte à près d'un siècle) dans le contexte de la collecte de données en ligne et à grande échelle.
	Notre but est d'apprendre un classement sur un ensemble d'objets à partir de comparaisons d'une façon \emph{efficace}: statistiquement, en matière de ressources de calcul et sur le plan de la quantité de données.

	Tout d'abord, nous examinons le problème algorithmique de l'estimation des paramètres du modèle à partir de données sous forme de comparaisons et cherchons à améliorer l'efficacité statistique et calculatoire des méthodes existantes.
	Notre contribution consiste à montrer qu'il est possible d'exprimer les paramètres qui maximisent la vraisemblance du modèle par la distribution stationnaire d'une chaîne de Markov.
	Ceci ouvre la voie à l'utilisation de programmes de résolution d'équations linéaires rapides ou à l'utilisation de méthodes itératives pour chaînes de Markov pour estimer les paramètres du modèle de Luce.

	Deuxièmement, nous développons une méthode économe en données pour apprendre un classement.
	Cette méthode consiste à choisir des paires d'objets à comparer de façon adaptive, en fonction des résultats de comparaisons observés précédemment.
	Nous commençons par montrer que Quicksort, un algorithme de tri connu, fonctionne bien même si les résultats des comparaisons sont bruités.
	Sous certaines hypothèses sur la distribution des paramètres du modèle, nous fournissons des bornes asymptotiques sur la qualité du classement retourné par Quicksort.
	En nous appuyant sur ce résultat, nous utilisons des algorithmes de tri comme point de départ d'une méthode simple et pratique d'apprentissage actif.
	Celle-ci donne de bons résultats sur des jeux de données du monde réel tout en utilisant seulement une petite fraction des ressources de calcul nécessaires aux méthodes concurrentes.

	Troisièmement, nous nous penchons sur un problème de choix structurés dans un réseau.
	Plus précisément, nous étudions un modèle où des utilisateurs naviguent sur un réseau (par exemple en suivant des liens sur le Web) et entreprenons d'apprendre les probabilités de transition sur les arêtes à partir d'observations limitées.
	Nous montrons que si les transitions suivent l'axiome de Luce, leur probabilité peut être déduite du trafic (marginal) à chaque nœud.
	Nous proposons un algorithme d'estimation des paramètres qui est robuste et qui admet une implémentation efficace en ressources de calcul.
	Notre méthode peut s'appliquer à des réseaux composés de milliards de nœuds et atteint de bons résultats pour la prédiction de flux de clics sur le Web.

	Au-delà des préférences humaines, les modèles probabilistes de comparaisons par paire peuvent aussi s'appliquer au sport.
	Pensez au football: deux équipes se comparent l'une à l'autre, et la meilleure des deux gagne.
	Dans la dernière partie de cette thèse, nous considérons un cas pratique et nous nous attaquons au problème de prédire les résultats de matchs entre équipes nationales.
	Ces équipes ne jouent que quelques matchs chaque année et de ce fait il est difficile de juger de leur force de façon précise.
	En observant que les joueurs appelés en sélection nationale jouent aussi les uns contre les autres dans leur club respectif, nous proposons une façon de surmonter cette difficulté en prenant en compte les matchs entre clubs (desquels il est facile d'obtenir une grande quantité).
	Notre méthode se base sur une projection des matchs dans un \emph{espace des joueurs} et s'appuie sur une procédure d'apprentissage économe en temps de calcul.
	Le modèle qui en résulte prédit les résultats de tournois internationaux d'une façon plus précise que d'autres modèles n'utilisant que les matchs entre équipes nationales.

	\paragraph{Mots-clés}
	comparaisons, choix, classements, modèles probabilistes, inférence statistique, algorithmes, apprentissage automatique, apprentissage actif, réseaux
\end{otherlanguage}

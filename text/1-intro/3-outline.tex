%! TEX root = ../thesis.tex
\section{Outline and Contributions}
\label{in:sec:outline}

% General contribution.
In this thesis, we seek to gain new insight into the structure and dynamics of social processes, such as peer-production, law-making, and voting.
To answer the research questions of Section~\ref{in:sec:motivation}, we
\begin{enumerate}
	\item collect \emph{rich} datasets,
	\item build \emph{interpretable} predictive models, and
	\item design \emph{efficient} learning algorithms.
\end{enumerate}
Our models are tailored to the datasets, and the learned parameters enable us to interpret their predictions, thereby gaining insight into the studied processes.
We also make our approaches practical and our results useful by deploying them on online Web platforms.

% \item Who are the important users and components in peer-production systems?
% \item What features of parliamentarians and laws increase the probability of law amendments being accepted?
% \item What ideological patterns are contained in voting data and how predictable are elections and referenda?
% \item How do people perceive the carbon footprint of their actions?
% \item How can we learn pairwise-comparison models of time-dependent data?

More specifically, in Chapter~\ref{ch:peerproduction}, we ask who are the important users and components in online peer-production systems.
We take a predictive viewpoint and posit that the probability of acceptance of user contributions depends on the skill of users and the inertia of components resisting to change.
We model this probability with a discrete-choice model inspired from the Rasch model, and we include latent factors reminiscent of collaborative filtering to capture non-linear interactions between users and components.
We apply our model to Wikipedia and to the Linux kernel, two examples of large-scale peer-production systems, and we discover interesting structures in the data:
We identify controversial Wikipedia articles and core Linux components that are crucial to the functioning of the system.
Finally, the latent factors boost the predictive performance and cluster well according to topics of the Wikipedia articles.

In Chapter~\ref{ch:lawmaking}, we shift our attention to law-making processes that we study through the lens of peer-production systems.
In the European Union, parliamentarians shape policies by proposing amendments to law drafts.
We look for features of the parliamentarians, the amendments, and the laws that increase the probability of amendments being accepted.
We start by collecting a new dataset of \numprint{450000} legislative edits proposed by European parliamentarians between 2009 and 2019.
Then, we predict the acceptance probability of amendments by building a model inspired from the multinomial logit model and the Rasch model.
Our approach takes advantage of the conflictive structure of amendments that modify the same parts of the same laws.
We identify that being in charge of a law draft and that proposing shorter amendments are among the features that correlate with highest probability of acceptance.
We also discover words and bigrams that are predictive of acceptance or rejection when inserted or deleted, such as the term ``human rights'' that predicts acceptance when deleted from the law.

In Chapter~\ref{ch:predikon}, we study one of the most fundamental choice processes in our society: voting.
To understand voting patterns, we develop an algorithm for predicting aggregate vote outcomes (\textit{e.g.}, national) from partial results (\textit{e.g.}, regional) that are revealed sequentially.
We combine matrix factorization and generalized linear models to obtain a flexible, efficient, and accurate algorithm.
Our experiments show that this approach accurately predicts the outcomes of Swiss referenda, U.S.\ presidential elections, and German legislative elections.
We also show that the learned latent factors correspond to clear ideological and cultural patterns, such as conservative/liberal and rural/urban patterns.
Finally, we deploy our algorithm on an online Web platform to provide real-time vote predictions in Switzerland and a data-visualization tool to explore voting behavior.

In Chapter~\ref{ch:climpact}, we study people's perception of their carbon footprint.
Driven by the observation that few people think of CO\textsubscript{2} impact in absolute terms, we design a system to probe their perception from simple pairwise comparisons of the relative carbon footprint of their actions.
We design a Web interface to collect 2000 answers from 200 users on our university campus.
We develop a Bayesian model inspired from the probit model that enables us to take an active-learning approach to selecting the pairs of actions that are maximally informative about the model parameters, hence making data collection more efficient.
The parameters capture the perceived carbon footprint of the actions and induce a natural ranking to compare them with the true values.
This reveals an interesting pattern:
Low-impact actions are usually overestimated and high-impact actions are usually underestimated.

Finally, in Chapter~\ref{ch:kickscore}, we address the problem of learning choices in a dynamic setting, where alternatives are correlated over time.
We solve this by replacing the static parameters of the logit model by continuous-time Gaussian processes, whose covariance function enables expressive time dynamics.
We develop an efficient inference algorithm that computes an approximate Bayesian posterior distribution.
Despite the flexibility of our model, our inference algorithm requires only a few linear-time iterations over the data.
We apply our model to several historical databases of sports outcomes and find that our approach (a) outperforms competing approaches in terms of predictive performance, (b) scales to millions of observations, and (c) generates compelling visualizations that help in understanding and interpreting the data.
We also develop a Web platform that uses our algorithm to make predictions for football matches in European leagues and international competitions.
